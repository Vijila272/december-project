{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Basic Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a \n",
    "Give a function F that takes a single argument n. This function should print a sequence of n strings as described in the examples below: <br>\n",
    "Ex: **n = 3**\n",
    "\n",
    "--A--<br>\n",
    "-BAB-<br>\n",
    "CBABC<br>\n",
    "\n",
    "**n = 4**\n",
    "\n",
    "---A---<br>\n",
    "--BAB--<br>\n",
    "-CBABC-<br>\n",
    "DCBABCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------A---------\n",
      "--------BAB--------\n",
      "-------CBABC-------\n",
      "------DCBABCD------\n",
      "-----EDCBABCDE-----\n",
      "----FEDCBABCDEF----\n",
      "---GFEDCBABCDEFG---\n",
      "--HGFEDCBABCDEFGH--\n",
      "-IHGFEDCBABCDEFGHI-\n",
      "JIHGFEDCBABCDEFGHIJ\n",
      "-----A-----\n",
      "----BAB----\n",
      "---CBABC---\n",
      "--DCBABCD--\n",
      "-EDCBABCDE-\n",
      "FEDCBABCDEF\n"
     ]
    }
   ],
   "source": [
    "def F(n):\n",
    "    for iteration in range(n):\n",
    "        current_pattern = \"\"\n",
    "        for position in range(2 * iteration + 1):\n",
    "            current_pattern += chr(65 + abs(position - iteration))\n",
    "        print('-' * (n - iteration - 1) + current_pattern + '-' * (n - iteration - 1))\n",
    "F(10)\n",
    "F(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b\n",
    "Make a function F that takes only one argument, a dictionary(dict) d.\n",
    "The keys of d are integers and the values of d are a tuple of type (x (int), y (int)).\n",
    "You must print out the dict in the format \"-key-, -x-, -y-\" with each entry in a new line. Print it for each of the three sorted orders, by key values ascending, by x values descending, by y values ascending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Items:\n",
      "1: (1, 2)\n",
      "2: (-1, 4)\n",
      "5: (-4, 3)\n",
      "4: (2, 3)\n",
      "\n",
      "Sorted by Key (Ascending):\n",
      "1: (1, 2)\n",
      "2: (-1, 4)\n",
      "4: (2, 3)\n",
      "5: (-4, 3)\n",
      "\n",
      "Sorted by X (Descending):\n",
      "4: (2, 3)\n",
      "1: (1, 2)\n",
      "2: (-1, 4)\n",
      "5: (-4, 3)\n",
      "\n",
      "Sorted by Y (Ascending):\n",
      "1: (1, 2)\n",
      "5: (-4, 3)\n",
      "4: (2, 3)\n",
      "2: (-1, 4)\n",
      "\n",
      "Dictionary Items:\n",
      "-8: (4, 2)\n",
      "6: (-3, 4)\n",
      "7: (2, 1)\n",
      "5: (9, -10)\n",
      "\n",
      "Sorted by Key (Ascending):\n",
      "-8: (4, 2)\n",
      "5: (9, -10)\n",
      "6: (-3, 4)\n",
      "7: (2, 1)\n",
      "\n",
      "Sorted by X (Descending):\n",
      "5: (9, -10)\n",
      "-8: (4, 2)\n",
      "7: (2, 1)\n",
      "6: (-3, 4)\n",
      "\n",
      "Sorted by Y (Ascending):\n",
      "5: (9, -10)\n",
      "7: (2, 1)\n",
      "-8: (4, 2)\n",
      "6: (-3, 4)\n"
     ]
    }
   ],
   "source": [
    "def print_sorted_dict(d):\n",
    "    print(\"Dictionary Items:\")\n",
    "    for key, (x, y) in d.items():\n",
    "        print(f\"{key}: ({x}, {y})\")\n",
    "\n",
    "    print(\"\\nSorted by Key (Ascending):\")\n",
    "    for key in sorted(d):\n",
    "        print(f\"{key}: ({d[key][0]}, {d[key][1]})\")\n",
    "\n",
    "    print(\"\\nSorted by X (Descending):\")\n",
    "    for key, (x, y) in sorted(d.items(), key=lambda item: item[1][0], reverse=True):\n",
    "        print(f\"{key}: ({x}, {y})\")\n",
    "\n",
    "    print(\"\\nSorted by Y (Ascending):\")\n",
    "    for key, (x, y) in sorted(d.items(), key=lambda item: item[1][1]):\n",
    "        print(f\"{key}: ({x}, {y})\")\n",
    "\n",
    "print_sorted_dict({1: (1, 2), 2: (-1, 4), 5: (-4, 3), 4: (2, 3)})\n",
    "print()\n",
    "print_sorted_dict({-8: (4, 2), 6: (-3, 4), 7: (2, 1), 5: (9, -10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Working with Student Records\n",
    "\n",
    "Use the data in **student_records.csv** to complete the given tasks. Do not include any external libraries. Use a Python dictionary if required.\n",
    "\n",
    "### Reference\n",
    "- [Python Dictionaries](https://www.w3schools.com/python/python_dictionaries.asp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a: open the student_records.csv file and print out the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   roll_number department  credit course_name      course_type grade\n",
      "0       588946         MA       3       EC250  hasmed_elective    AB\n",
      "1       145372         EP       4       EP407  hasmed_elective    CC\n",
      "2       834515         MA       8       EP885  hasmed_elective    BB\n",
      "3       344265        CSE       6      CSE699          honours    AB\n",
      "4       358405         MA       3       EE460            minor    AP\n",
      "5       781075         CE       8       CE540          honours    CC\n",
      "6       180828        CSE       6       CE880            minor    AB\n",
      "7       981238         MM       4      CSE226            minor    AB\n",
      "8       836881         MM       8       MM530             core    AA\n",
      "9       310604         EE       8       EE202             core    AB\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "import pandas as pd\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('/Users/vijila/student_records-2.csv')     #This is the current address of that file\n",
    "\n",
    "# Print the first 10 rows\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.b: Print out the total credits and calculte CPI of each student. \n",
    "CPI is the weighted average of core courses, and electives (weights being the letter grades converted to number AP,AA=10, AB=9, BB=8, BC=7, CC=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    roll_number  total_credit  total_score       cpi\n",
      "0        124663            59          498  8.440678\n",
      "1        138296            28          227  8.107143\n",
      "2        143142            70          596  8.514286\n",
      "3        143856            70          609  8.700000\n",
      "4        144528            56          481  8.589286\n",
      "..          ...           ...          ...       ...\n",
      "95       981238            93          784  8.430108\n",
      "96       986057            56          438  7.821429\n",
      "97       993835            27          238  8.814815\n",
      "98       995208            49          385  7.857143\n",
      "99       998293            64          571  8.921875\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wq/qy2mxf5n0xz3xq9pw609dfgw0000gp/T/ipykernel_49247/1708029198.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_records['weighted_score'] = filtered_records['credit'] * filtered_records['grade_number']\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load student records from CSV file\n",
    "student_records = pd.read_csv('/Users/vijila/student_records-2.csv')\n",
    "\n",
    "# Define grade mapping\n",
    "grade_mapping = {'AP': 10, 'AA': 10, 'AB': 9, 'BB': 8, 'BC': 7, 'CC': 6}\n",
    "\n",
    "# Map grades to grade numbers\n",
    "student_records['grade_number'] = student_records['grade'].map(grade_mapping)\n",
    "\n",
    "# Filter courses\n",
    "courses = ['core', 'hasmed_elective']\n",
    "filtered_records = student_records[student_records['course_type'].isin(courses)]\n",
    "\n",
    "# Calculate weighted score\n",
    "filtered_records['weighted_score'] = filtered_records['credit'] * filtered_records['grade_number']\n",
    "\n",
    "# Group by roll number and calculate CPI\n",
    "cpi_data = filtered_records.groupby('roll_number').agg(\n",
    "    total_credit=('credit', 'sum'),\n",
    "    total_score=('weighted_score', 'sum')\n",
    ")\n",
    "cpi_data['cpi'] = cpi_data['total_score'] / cpi_data['total_credit']\n",
    "\n",
    "# Reset index\n",
    "cpi_data.reset_index(inplace=True)\n",
    "\n",
    "# Print CPI data\n",
    "print(cpi_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.c: Print out the roll numbers of all students who meet the graduation requirements \n",
    "Atleast 20 credist of core course, 15 credits of department elective, 10 credits of flexible elective and 5 credits of hasmed electives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students meeting graduation requirements:\n",
      "[124663, 143142, 143856, 144528, 150503, 159438, 180828, 203200, 207443, 214270, 265922, 282482, 283796, 294697, 310604, 327122, 362471, 379479, 381227, 388969, 391848, 461971, 482623, 485484, 488661, 500658, 517837, 521087, 534763, 571782, 572815, 581065, 581858, 588946, 608522, 608952, 626000, 628849, 630568, 681499, 692318, 703403, 716985, 721490, 750259, 773982, 781075, 782129, 787967, 810863, 834515, 836881, 845623, 871746, 879634, 881983, 888886, 928288, 955757, 960395, 970791, 971123, 973158, 981238, 986057, 998293]\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('/Users/vijila/student_records-2.csv')\n",
    "\n",
    "graduation_requirements = {\n",
    "    'core': 20,\n",
    "    'department_elective': 15,\n",
    "    'flexible_elective': 10,\n",
    "    'hasmed_elective': 5\n",
    "}\n",
    "\n",
    "credits = data.groupby(['roll_number', 'course_type'])['credit'].sum().unstack(fill_value=0)\n",
    "\n",
    "def is_eligible_for_graduation(credits, requirements):\n",
    "    return all(credits.get(course_type, 0) >= requirement for course_type, requirement in requirements.items())\n",
    "\n",
    "eligible_students = credits[credits.apply(is_eligible_for_graduation, args=(graduation_requirements,), axis=1)]\n",
    "\n",
    "print(\"Students meeting graduation requirements:\")\n",
    "print(eligible_students.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.d: Print out the roll numbers of all students who completed a minor \n",
    "Atleast 10 credits with minor tag in a specific department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    roll_number department  credit\n",
      "0        124663         EE      37\n",
      "1        138296         MM      29\n",
      "2        143142        CSE      30\n",
      "3        143856         CE      35\n",
      "4        144528         ME      23\n",
      "..          ...        ...     ...\n",
      "95       981238         MM      22\n",
      "96       986057         ME      13\n",
      "97       993835         CE      34\n",
      "98       995208         ME      24\n",
      "99       998293         ME      12\n",
      "\n",
      "[96 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_student_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def filter_minor_courses(data_frame):\n",
    "    return data_frame[data_frame['course_type'] == 'minor']\n",
    "\n",
    "def calculate_minor_credits(minor_courses):\n",
    "    return minor_courses.groupby(['roll_number', 'department'])['credit'].sum().reset_index()\n",
    "\n",
    "def filter_students_with_minor(minor_credits, min_credits):\n",
    "    return minor_credits[minor_credits['credit'] >= min_credits]\n",
    "\n",
    "file_path = '/Users/vijila/student_records-2.csv'\n",
    "data_frame = load_student_data(file_path)\n",
    "minor_courses = filter_minor_courses(data_frame)\n",
    "minor_credits = calculate_minor_credits(minor_courses)\n",
    "students_with_minor = filter_students_with_minor(minor_credits, 10)\n",
    "print(students_with_minor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.e: Print out the roll numbers of all students who completed a honours\n",
    "Atleast 10 credits with honours tag and 20 core credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students who completed honors and core credits:\n",
      "Empty DataFrame\n",
      "Columns: [roll_number, honors_credits, core_credits]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load student records from CSV file\n",
    "student_records = pd.read_csv('/Users/vijila/student_records-2.csv')\n",
    "\n",
    "# Separate honors and core courses\n",
    "honors_courses = student_records[student_records['course_type'] == 'honors']\n",
    "core_courses = student_records[student_records['course_type'] == 'core']\n",
    "\n",
    "# Calculate total credits for honors and core courses\n",
    "honors_credits_total = honors_courses.groupby('roll_number')['credit'].sum()\n",
    "core_credits_total = core_courses.groupby('roll_number')['credit'].sum()\n",
    "\n",
    "# Create a DataFrame to store total credits for each student\n",
    "student_credits = pd.DataFrame({\n",
    "    'honors_credits': honors_credits_total,\n",
    "    'core_credits': core_credits_total\n",
    "})\n",
    "\n",
    "# Identify students who completed at least 10 honors credits and 20 core credits\n",
    "eligible_students = student_credits[\n",
    "    (student_credits['honors_credits'] >= 10) &\n",
    "    (student_credits['core_credits'] >= 20)\n",
    "]\n",
    "\n",
    "# Display roll numbers of eligible students\n",
    "print(\"Students who completed honors and core credits:\")\n",
    "print(eligible_students.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SciPy** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A\n",
    "Minimize the function $f(x, y) = 2(x - y - 3)^2 + 4(x + 2y + 1)^4$.<br>\n",
    "With the constraints : $ x - y \\ge -3, (x + 2)^2 + (y + 1)^2 \\le 5$ <br>\n",
    "Using scipy.optimize.minimize with constraints. (Hint: Look at the examples in the official documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points at which function is minimized: [ 0.23492507 -0.92851619]\n",
      "Function minimum value: 7.345026153553158\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def objective_function(xy):\n",
    "    x, y = xy\n",
    "    return 2*(x - y - 3)**2 + 4*(x + 2*y + 1)**4\n",
    "\n",
    "def constraint_1(xy):\n",
    "    x, y = xy\n",
    "    return x - y + 3\n",
    "\n",
    "def constraint_2(xy):\n",
    "    x, y = xy\n",
    "    return 5 - (x + 2)**2 - (y + 1)**2\n",
    "\n",
    "constraints = [{'type': 'ineq', 'fun': constraint_1},\n",
    "               {'type': 'ineq', 'fun': constraint_2}]\n",
    "\n",
    "initial_guess = [1, 1]\n",
    "result = minimize(objective_function, initial_guess, constraints=constraints)\n",
    "\n",
    "print(\"Points at which function is minimized:\", result.x)\n",
    "print(\"Function minimum value:\", result.fun)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B\n",
    "Evaluate the line integral of the function $f(x, y) = x^2 + y^4$ along the circle $ x^2 + y^2 = 3 $ anticlockwise (scalar integral, not vector). You must use scipy for integration but you may use parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.15421508651228\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "\n",
    "def calculate_curve_length():\n",
    "    def f(x, y):\n",
    "        return x**2 + y**4\n",
    "\n",
    "    def parametric_x(t):\n",
    "        return np.sqrt(3) * np.cos(t)\n",
    "\n",
    "    def parametric_y(t):\n",
    "        return np.sqrt(3) * np.sin(t)\n",
    "\n",
    "    def curve_integrand(t):\n",
    "        return (parametric_x(t))**2 + (parametric_y(t))**4 * np.sqrt((parametric_x(t))**2 + (parametric_y(t))**2)\n",
    "\n",
    "    result, error = quad(curve_integrand, 0, 2*np.pi)\n",
    "    return result\n",
    "\n",
    "curve_length = calculate_curve_length()\n",
    "print(curve_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Numpy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Lisan_Al_Gaib.pdf for problem description and complete the following functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # to time the execution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -2.127299405763187323e+00  1.753571532049580384e+00\n",
      "0                   -0.340030                 -0.006708\n",
      "1                   -3.219907                 -2.220027\n",
      "2                   -3.709582                  1.330881\n",
      "3                   -0.994425                  0.540363\n",
      "4                   -3.897078                  1.849549\n",
      "5                    0.162213                 -1.938304\n",
      "6                   -3.090875                 -2.082977\n",
      "7                   -2.478789                 -0.376218\n",
      "8                   -1.840275                 -1.543854\n",
      "9                   -0.940736                 -2.302531\n",
      "10                  -2.539277                 -1.168191\n",
      "11                  -1.719650                  0.925880\n",
      "12                  -3.001631                 -0.428828\n",
      "13                  -1.037927                 -2.767748\n",
      "14                  -0.962276                 -2.147379\n",
      "15                  -3.674742                  1.744428\n",
      "16                   0.828160                  1.041987\n",
      "17                  -2.476931                 -2.511639\n",
      "18                  -0.578835                 -0.799238\n",
      "19                  -3.389809                 -0.524115\n",
      "20                  -3.828057                  1.546602\n",
      "21                  -2.706100                  0.312611\n",
      "22                  -2.441445                 -0.399660\n",
      "23                  -1.266449                 -2.075728\n",
      "24                   0.847923                  0.875664\n",
      "25                   0.697495                  1.474137\n",
      "26                  -1.010500                  1.609371\n",
      "27                  -3.557537                 -2.020086\n",
      "28                  -3.773864                 -1.373348\n",
      "29                   3.943386                  4.356745\n",
      "30                   6.143688                  4.783767\n",
      "31                   3.404673                  5.713480\n",
      "32                   2.704621                  7.010985\n",
      "33                   2.372753                  7.934435\n",
      "34                   5.861224                  3.993578\n",
      "35                   2.027611                  7.077307\n",
      "36                   5.534287                  6.645036\n",
      "37                   5.856352                  3.370223\n",
      "38                   3.792329                  3.579345\n",
      "39                   6.315517                  6.116491\n",
      "40                   3.654490                  3.317792\n",
      "41                   3.554912                  4.625917\n",
      "42                   5.648031                  6.187787\n",
      "43                   6.436064                  5.361075\n",
      "44                   2.597971                  6.566224\n",
      "45                   5.803925                  5.806386\n",
      "46                   5.854836                  5.468978\n",
      "47                   4.613664                  5.137705\n",
      "48                   2.127096                  3.539457\n",
      "49                   2.157146                  6.182052\n",
      "50                   3.571780                  5.542853\n",
      "51                   6.537832                  4.246461\n",
      "52                   4.051915                  6.777756\n",
      "53                   3.143991                  3.384900\n",
      "54                   3.448757                  3.806106\n",
      "55                   6.648488                  7.040602\n",
      "56                   5.167019                  7.357303\n",
      "57                   6.018360                  3.932850\n",
      "58                   6.462795                  5.696711\n"
     ]
    }
   ],
   "source": [
    "### TODO 1\n",
    "### Load data from data_path\n",
    "### Check the input file spice_locations.txt to understand the Data Format\n",
    "### Return : np array of size Nx2\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        return pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    file_path = 'spice_locations.txt'\n",
    "    spice_data = load_data(file_path)\n",
    "    if spice_data is not None:\n",
    "        print(spice_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly Initialized Centroids:\n",
      " [[-2.12729941  1.75357153]\n",
      " [-3.89707753  1.84954926]\n",
      " [ 2.02761059  7.07730714]]\n",
      "Predefined Centroids:\n",
      " [[ 1.   6. ]\n",
      " [-3.   1. ]\n",
      " [ 8.   5.5]]\n"
     ]
    }
   ],
   "source": [
    "### TODO 2.1\n",
    "### If init_centers is None, initialize the centers by selecting K data points at random without replacement\n",
    "### Else, use the centers provided in init_centers\n",
    "### Return : np array of size Kx2\n",
    "def load_dataset(file_path): \n",
    "    try: \n",
    "        return np.genfromtxt(file_path, delimiter=\",\") \n",
    "    except FileNotFoundError: \n",
    "        print(f\"Error: The file '{file_path}' was not found.\") \n",
    "        return None \n",
    "    except np.core._exceptions._ArrayMemoryError: \n",
    "        print(f\"Error: Insufficient memory to load the data from '{file_path}'.\") \n",
    "        return None \n",
    "    except Exception as e: \n",
    "        print(f\"An unexpected error occurred: {e}\") \n",
    "        return None \n",
    "\n",
    "def initialize_cluster_centroids(data, num_clusters, custom_centroids=None, seed=42): \n",
    "    if custom_centroids is None: \n",
    "        np.random.seed(seed) \n",
    "        indices = np.random.choice(data.shape[0], num_clusters, replace=False) \n",
    "        return data[indices] \n",
    "    else: \n",
    "        return custom_centroids \n",
    "\n",
    "def validate_data(data, num_clusters): \n",
    "    if data is None: \n",
    "        raise ValueError(\"Data is None\") \n",
    "    if num_clusters <= 0: \n",
    "        raise ValueError(\"Number of clusters must be greater than 0\") \n",
    "    if data.shape[0] < num_clusters: \n",
    "        raise ValueError(\"Number of data points is less than the number of clusters\") \n",
    "\n",
    "def main(): \n",
    "    file_path = 'spice_locations.txt' \n",
    "    num_clusters = 3 \n",
    "    data = load_dataset(file_path) \n",
    "    validate_data(data, num_clusters) \n",
    "    cluster_centroids = initialize_cluster_centroids(data, num_clusters) \n",
    "    print(\"Randomly Initialized Centroids:\\n\", cluster_centroids) \n",
    "    custom_centroids = np.array([[1.0, 6.0], [-3.0, 1.0], [8, 5.5]]) \n",
    "    predefined_cluster_centroids = initialize_cluster_centroids(data, num_clusters, custom_centroids=custom_centroids) \n",
    "    print(\"Predefined Centroids:\\n\", predefined_cluster_centroids) \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Initialization Complete.\n",
      "Labels Shape: (59,)\n",
      "Labels:\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "### TODO 2.2\n",
    "### Initialize the labels to all ones to size (N,) where N is the number of data points\n",
    "### Return : np array of size N\n",
    "def initialise_labels(data): \n",
    "    return np.ones(data.shape[0], dtype=int)\n",
    "\n",
    "data_path = '/Users/vijila/spice_locations.txt'\n",
    "data = load_data(data_path)\n",
    "\n",
    "if data is not None:\n",
    "    labels = initialise_labels(data)\n",
    "    print(\"Labels Initialization Complete.\")\n",
    "    print(\"Labels Shape:\", labels.shape)\n",
    "    print(\"Labels:\\n\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance Matrix:\n",
      "[[1.15298202 1.8888535 ]\n",
      " [1.06256524 0.66003401]\n",
      " [3.91105561 2.53309218]]\n"
     ]
    }
   ],
   "source": [
    "### TODO 3.1 : E step\n",
    "### For Each data point, find the distance to each center\n",
    "### Return : np array of size NxK\n",
    "def calculate_distances(data, centers):\n",
    "    diff = data[:, np.newaxis, :] - centers[np.newaxis, :, :]\n",
    "    dist = np.linalg.norm(diff, axis=2)\n",
    "    return dist\n",
    "\n",
    "points = np.array([\n",
    "    [1.1273, 2.7535],\n",
    "    [2.3400, 3.0067],\n",
    "    [4.2199, 5.2200],\n",
    "])\n",
    "\n",
    "centers = np.array([\n",
    "    [2.0, 2.0],\n",
    "    [3.0, 3.0],\n",
    "])\n",
    "\n",
    "dist_matrix = calculate_distances(points, centers)\n",
    "\n",
    "print(\"Euclidean Distance Matrix:\")\n",
    "print(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster IDs: [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "### TODO 3.2 : E step\n",
    "### For Each data point, assign the label of the nearest center\n",
    "### Return : np array of size N\n",
    "import numpy as np\n",
    "\n",
    "def update_labels(distances):   \n",
    "    \"\"\"Assign each point to the nearest cluster.\"\"\"\n",
    "    clusters = np.argmin(distances, axis=1)\n",
    "    return clusters\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    points = np.array([\n",
    "        [2.74, 3.18],\n",
    "        [0.34, 1.42],\n",
    "        [3.85, 4.86]\n",
    "    ])\n",
    "\n",
    "    cluster_ids = update_labels(points)\n",
    "    print(\"Cluster IDs:\", cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Centers:\n",
      "[[1.16666667 1.46666667]\n",
      " [7.33333333 9.        ]]\n"
     ]
    }
   ],
   "source": [
    "### TODO 4 : M step\n",
    "### Update the centers to the mean of the data points assigned to it\n",
    "### Return : np array of size Kx2\n",
    "def update_centers(data, labels, K): \n",
    "\n",
    "    dimensionality = data.shape[1] \n",
    "    updated_centers = np.zeros((K, dimensionality)) \n",
    "    for cluster_index in range(K): \n",
    "        points_in_cluster = data[np.where(labels == cluster_index)] \n",
    "        if len(points_in_cluster) > 0: \n",
    "            updated_centers[cluster_index] = np.mean(points_in_cluster, axis=0) \n",
    "        else: \n",
    "            updated_centers[cluster_index] = np.zeros(dimensionality) \n",
    "    return updated_centers\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    points = np.array([\n",
    "        [1.0, 2.0],\n",
    "        [1.5, 1.8],\n",
    "        [5.0, 8.0],\n",
    "        [8.0, 8.0],\n",
    "        [1.0, 0.6],\n",
    "        [9.0, 11.0],\n",
    "    ])\n",
    "    targets = np.array([0, 0, 1, 1, 0, 1])\n",
    "    k = 2\n",
    "    new_centers = update_centers(points, targets, k)\n",
    "    print(\"Updated Centers:\")\n",
    "    print(new_centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termination status: False\n",
      "Termination status: True\n",
      "Termination status: True\n"
     ]
    }
   ],
   "source": [
    "### TODO 6 : Check convergence\n",
    "### Check if the labels have changed from the previous iteration\n",
    "### Return : True / False\n",
    "def check_termination(previous_labels, current_labels, previous_matrix, current_matrix): \n",
    "    \"\"\"Determine if the labels or matrix have undergone a change.\"\"\"\n",
    "    return not (np.array_equal(previous_labels, current_labels) and np.array_equal(previous_matrix, current_matrix))\n",
    "\n",
    "# Example 1: Labels and matrix remain unchanged\n",
    "previous_labels = np.array([2, 3, 2, 3, 2])\n",
    "current_labels = np.array([2, 3, 2, 3, 2])\n",
    "previous_matrix = np.array([[1, 2], [3, 4]])\n",
    "current_matrix = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "termination_status = check_termination(previous_labels, current_labels, previous_matrix, current_matrix)\n",
    "print(\"Termination status:\", termination_status)\n",
    "\n",
    "# Example 2: Labels have undergone a change\n",
    "previous_labels = np.array([2, 3, 2, 3, 2])\n",
    "current_labels = np.array([2, 3, 3, 3, 2])\n",
    "previous_matrix = np.array([[1, 2], [3, 4]])\n",
    "current_matrix = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "termination_status = check_termination(previous_labels, current_labels, previous_matrix, current_matrix)\n",
    "print(\"Termination status:\", termination_status)\n",
    "\n",
    "# Example 3: Matrix has undergone a change\n",
    "previous_labels = np.array([2, 3, 2, 3, 2])\n",
    "current_labels = np.array([2, 3, 2, 3, 2])\n",
    "previous_matrix = np.array([[1, 2], [3, 4]])\n",
    "current_matrix = np.array([[1, 2], [3, 5]])\n",
    "\n",
    "termination_status = check_termination(previous_labels, current_labels, previous_matrix, current_matrix)\n",
    "print(\"Termination status:\", termination_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DON'T CHANGE ANYTHING IN THE FOLLOWING FUNCTION\n",
    "def kmeans(data_path:str, K:int, init_centers):\n",
    "    '''\n",
    "    Input :\n",
    "        data (type str): path to the file containing the data\n",
    "        K (type int): number of clusters\n",
    "        init_centers (type numpy.ndarray): initial centers. shape = (K, 2) or None\n",
    "    Output :\n",
    "        centers (type numpy.ndarray): final centers. shape = (K, 2)\n",
    "        labels (type numpy.ndarray): label of each data point. shape = (N,)\n",
    "        time (type float): time taken by the algorithm to converge in seconds\n",
    "    N is the number of data points each of shape (2,)\n",
    "    '''\n",
    "    data = load_data(data_path)    \n",
    "    centers = initialise_centers(data, K, init_centers)\n",
    "    labels = initialise_labels(data)\n",
    "\n",
    "    start_time = time.time() # Time stamp \n",
    "\n",
    "    while True:\n",
    "        distances = calculate_distances(data, centers)\n",
    "        labels_new = update_labels(distances)\n",
    "        centers = update_centers(data, labels_new, K)\n",
    "        if check_termination(labels, labels_new): break\n",
    "        else: labels = labels_new\n",
    " \n",
    "    end_time = time.time() # Time stamp after the algorithm ends\n",
    "    return centers, labels, end_time - start_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO 7\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualise(data_path, labels, centers):\n",
    "    data = load_data(data_path)\n",
    "\n",
    "    # Scatter plot of the data points\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=labels, s=50, cmap='viridis')\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)\n",
    "\n",
    "    # Set the title and axis labels\n",
    "    plt.title('K-means clustering')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig('kmeans.png')\n",
    "\n",
    "    ## DO NOT CHANGE THE FOLLOWING LINE\n",
    "    return plt\n",
    "\n",
    "\n",
    "def initialise_centers(data, K, init_centers=None):\n",
    "    if init_centers is None:\n",
    "        # Randomly select K data points without replacement\n",
    "        centers = data[np.random.choice(data.shape[0], K, replace=False)]\n",
    "    else:\n",
    "        # Use the provided initial centers\n",
    "        centers = init_centers\n",
    "    return centers\n",
    "\n",
    "\n",
    "def update_centers(data, labels, K):\n",
    "    return np.array([data[labels == k].mean(axis=0) for k in range(K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### After you have completed the above functions, run the following code to generate the plot\n",
    "data_path = '/Users/vijila/spice_locations.txt'\n",
    "K, init_centers = 2, None\n",
    "centers, labels, time_taken = kmeans(data_path, K, init_centers)\n",
    "print('Time taken for the algorithm to converge:', time_taken)\n",
    "visualise(data_path, labels, centers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
